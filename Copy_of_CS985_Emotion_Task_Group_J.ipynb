{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Er-Devjyoti/Er-Devjyoti/blob/main/Copy_of_CS985_Emotion_Task_Group_J.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cs985-987-Emotion-Recognition-Project\n",
        "\n",
        "## Group J - Devjyoti Das\n",
        "\n",
        "\n",
        "### Dataset Description\n",
        "The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral).\n",
        "\n",
        "train.csv contains two columns, \"emotion\" and \"pixels\". The \"emotion\" column contains a numeric code ranging from 0 to 6, inclusive, for the emotion that is present in the image. The \"pixels\" column contains a string surrounded in quotes for each image. The contents of this string a space-separated pixel values in row major order. test.csv contains only the \"pixels\" column and your task is to predict the emotion column.\n",
        "\n",
        "The training set consists of 28,709 examples. The public test set used for the leaderboard consists of 3,589 examples. The final test set, which was used to determine the winner of the competition, consists of another 3,589 examples.\n",
        "\n",
        "They have graciously provided the workshop organizers with a preliminary version of their dataset to use for this contest.\n"
      ],
      "metadata": {
        "id": "TYqXsClKkAzP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Overview:\n",
        "\n",
        "The Emotion recognition task starts with exploration of the categorical dataset. This task has 7 output categories and these categories are predicted at the output. Now, the images in the dataset is stored in numbered pixel format and has 27752 unique values. There are 7 emotions in the dataset and the shape of the labels are (29000, 7).\n",
        "\n",
        "According to the task our approach is straight forward. and we have tried to implement 3 different models namely, standard Ml, DNN Model and lastly transfer Learning. Since this is a numerical based categorical data and there can be irregularities. Thus, we have conducted a pre data analysis and PCA (limited columns) on the dataset."
      ],
      "metadata": {
        "id": "bwytF5pwk_8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Standard ML Baseline\n",
        "Algorithms covered:\n",
        "1. Logistic Regression\n",
        "2. Random Forest\n",
        "3. Support Vector Machine"
      ],
      "metadata": {
        "id": "kfmQsD--bVvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Method\n",
        "The exploration of the dataset has showed us few effects when using any ML model:\n",
        "\n",
        "\n",
        "1.   The dataset is non-linear and arbitary in nature. That can be explained due to the pixels column in the data.  \n",
        "\n",
        "2.   If we remove the Id column there can be mostly negative effect on the models since the models uses Id in some manner to deduce the categories. \n",
        "\n",
        "3. We also tried to pre-process the data using normalizationa and augmentation since it is already a gray scale image pixel representation. However, the data is in string format and hence we decided to convert into an array format. \n",
        "\n",
        "4. Though standard scalar normalization helps the ML models for better accuracy. The data augmentation worsenes the output. Thus we have not included the augmentation. \n",
        "\n",
        "5. To train the data better and test it initially we have also splitted the data into train and validation for prior preformance knowledge. \n",
        "\n",
        "6. For feature reduction we have also included the PCA that helps us to further improve the ML algo performance."
      ],
      "metadata": {
        "id": "EicKAINhex3_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18xRfnGZuX4-",
        "outputId": "dd88bc10-375a-4207-d17f-4f25423d3fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML Algorithm Used\n",
        "The basic ML model has been based on 3 different algorithm namely, Logistic Regression, Random Forest and SVM. All these 3 models were chosen over other ML models after rigorously testing the dataset (with and without augmenttation) and we are only including the top 3 performing models.\n",
        "\n",
        "We are using the sklearn libraries to call the preprocessing and Ml models.\n",
        "\n",
        "Firstly, we are using non-linear and categorical Ml algoritms as per our dataset. We are not fine tuning the basic model further since we would be using more complex models ahead like DNN and Transfer Learning that can give us better results."
      ],
      "metadata": {
        "id": "6UKPsOXLgxR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import keras.backend as K"
      ],
      "metadata": {
        "id": "O_Nuq-k2cC0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load train and test data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/my_emotion_train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/my_emotion_test.csv')\n"
      ],
      "metadata": {
        "id": "XJ2qMXQncb_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split train data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_data[\"pixels\"], train_data[\"emotion\"], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "V8qOV5AOjoIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "X_train = np.array([np.fromstring(x, dtype=int, sep=' ') for x in X_train])\n",
        "X_val = np.array([np.fromstring(x, dtype=int, sep=' ') for x in X_val])\n",
        "test_data = np.array([np.fromstring(x, dtype=int, sep=' ') for x in test_data[\"pixels\"]])\n"
      ],
      "metadata": {
        "id": "MYsFMHxXjIjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "test_data = scaler.transform(test_data)\n"
      ],
      "metadata": {
        "id": "YQB9_4YJjKFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform PCA for feature reduction\n",
        "pca = PCA(n_components=0.88, random_state=60)\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_val = pca.transform(X_val)\n",
        "test_data = pca.transform(test_data)\n"
      ],
      "metadata": {
        "id": "m819o5jEjLZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and evaluate logistic regression\n",
        "lr = Pipeline(steps=[('lr', LogisticRegression())])\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_val)\n",
        "\n",
        "#mean = K.mean(y_pred_lr)\n",
        "#std = K.std(y_pred_lr)\n",
        "\n",
        "#print('Mean:', mean)\n",
        "#print('Standard deviation:', std)\n",
        "print(\"Logistic Regression accuracy:\", accuracy_score(y_val, y_pred_lr))\n"
      ],
      "metadata": {
        "id": "m3NonNhrjMwE",
        "outputId": "f14b29d6-4acd-435c-d0c9-5132062d91b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression accuracy: 0.3793103448275862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train and evaluate random forest\n",
        "rf = Pipeline(steps=[('rf', RandomForestClassifier())])\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_val)\n",
        "\n",
        "# Compute the mean and standard deviation of the output\n",
        "#mean = K.mean(y_pred_rf)\n",
        "#std = K.std(y_pred_rf)\n",
        "\n",
        "#print('Mean:', mean)\n",
        "#print('Standard deviation:', std)\n",
        "print(\"Random Forest accuracy:\", accuracy_score(y_val, y_pred_rf))\n"
      ],
      "metadata": {
        "id": "mtictVA_jOUP",
        "outputId": "d1ba4c54-0e4f-4d31-b35b-1ad9e8f4e29d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest accuracy: 0.4232758620689655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train and evaluate support vector machine\n",
        "svm = Pipeline(steps=[('svm', SVC())])\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Get the output of the model\n",
        "#output = svm.predict(X_test)\n",
        "\n",
        "# Compute the mean and standard deviation of the output\n",
        "#mean = K.mean(output)\n",
        "#std = K.std(output)\n",
        "\n",
        "#print('Mean:', mean)\n",
        "#print('Standard deviation:', std)\n",
        "\n",
        "y_pred_svm = svm.predict(X_val)\n",
        "print(\"Support Vector Machine accuracy:\", accuracy_score(y_val, y_pred_svm))\n"
      ],
      "metadata": {
        "id": "9GoUUYuJjP3E",
        "outputId": "07619a51-39f6-4f28-8fb3-fd0b83111ef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine accuracy: 0.44189655172413794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions on test data using the best model\n",
        "test_preds = rf.predict(test_data)\n",
        "\n",
        "# save predictions to a file\n",
        "submission = pd.DataFrame({'id': range(len(test_data)), 'emotion': test_preds})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "mdlLoxWnwsRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep NN models\n",
        "\n",
        "For this DNN model multiple different configurations were tried with different combinations of layers and neurons. The first thing that was done was to use a Flatten layer to make the multidimensional input of the images one-dimensional. Since our dataset consists of images of size 48x48x1 (grayscale), we initialised the model with a layer with neurons equal the size of the input which is 2304 (48x48). In this way each neuron in the input layer corresponds to a single pixel in the images. The activation function that is used is the ReLU. The ReLU activation outputs the input directly if it is positive, or a zero if the input is zero or negative. It is one of the most popular activation functions due to its advantages of [1] computational simplicity, linear behaviour even though it is a non-linear function, and its ability to output a true zero value, unlike other activation functions like the sigmoid which only approximates a value close to zero. These are the major reasons why ReLU was chosen. \n",
        "\n",
        "7 hidden layers follow the input layer. The number of hidden layers is purely based on trial and error and is the one that gave us the best accuracy out of all different configurations tried. The choice of the number of neurons of each layer is based on the rule-of-thumb [2], which states that the number of neurons of hidden layers must be between the size of the input layer and the size of the output layer, and also it must be around 2/3 the size of the input layer plus the output layer. Here the first hidden layer has 2000 neurons as it was found to perform better than the 1536 neurons which is the 2/3 of the input. After that the number of neurons gradually reduces in subsequent hidden layers as we move closer to the output. \n",
        "\n",
        "Since the dataset has 7 different output classes, 1 for each emotion, the output layer has 7 neurons, one for each class. The softmax activation function is used here to normalise the outputs by converting them into a vector that the weighted sum equals one and so the output can be considered as probabilities [3]. \n",
        "\n",
        "To prevent overfitting we made use of dropout after each layer.The model was compiled using a relatively small learning rate of 0.0001 as larger ones were creating an unwanted divergent behaviour in the validation accuracy and the loss."
      ],
      "metadata": {
        "id": "wR3V690DcJsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, UpSampling2D, Input, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "import keras.backend as K\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "GVEES7p4cTZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9bYYS4J7cr4V",
        "outputId": "4e820c6d-39ad-4a56-8eed-525f7b9547ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"/content/drive/MyDrive/my_emotion_train.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/my_emotion_test.csv\")\n"
      ],
      "metadata": {
        "id": "_B3zdPeWcu9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(data):\n",
        "    data = data.pixels.apply(lambda x: np.array(x.split()).reshape(48, 48, 1).astype('float32'))\n",
        "    data = np.stack(data, axis=0)\n",
        "    data.shape\n",
        "    return data / 255.0\n"
      ],
      "metadata": {
        "id": "PCe50ZPii4_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = preprocess_images(train_data)\n",
        "test_images = preprocess_images(test_data)\n",
        "print('Train images shape:', (train_images.shape))\n",
        "print('Test images shape:', (test_images.shape))\n"
      ],
      "metadata": {
        "id": "j49DEssei6rq",
        "outputId": "d6e1e692-21c4-4e45-fc15-7db4809d1974",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images shape: (29000, 48, 48, 1)\n",
            "Test images shape: (6887, 48, 48, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = train_data.emotion\n",
        "\n",
        "# Splitting the training data to training and validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_images, y, test_size=0.2, random_state=42)\n",
        "print('Train set shape: X=%s, y=%s' % (X_train.shape, y_train.shape))\n",
        "print('Validation set shape: X=%s, y=%s' % (X_valid.shape, y_valid.shape))\n"
      ],
      "metadata": {
        "id": "OH986FKci8Jj",
        "outputId": "3d5fe62e-6ab2-4665-9115-cd571c6bbd04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: X=(23200, 48, 48, 1), y=(23200,)\n",
            "Validation set shape: X=(5800, 48, 48, 1), y=(5800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN = tf.keras.Sequential()\n",
        "model_DNN.add(Flatten(input_shape=(48,48,1)))\n",
        "model_DNN.add(Dense(2304, activation='relu'))\n",
        "#model_DNN.add(BatchNormalization())\n",
        "model_DNN.add(Dense(2000, activation='relu'))\n",
        "#model_DNN.add(BatchNormalization())\n",
        "model_DNN.add(Dropout(0.35))\n",
        "model_DNN.add(Dense(1750, activation='relu'))\n",
        "#model_DNN.add(BatchNormalization())\n",
        "model_DNN.add(Dropout(0.35))\n",
        "model_DNN.add(Dense(1500, activation='relu'))\n",
        "#model_DNN.add(BatchNormalization())\n",
        "model_DNN.add(Dropout(0.25))\n",
        "model_DNN.add(Dense(1500, activation='relu'))\n",
        "#model_DNN.add(BatchNormalization())\n",
        "model_DNN.add(Dropout(0.25))\n",
        "model_DNN.add(Dense(1000, activation='relu'))\n",
        "#model_DNN.add(BatchNormalization())\n",
        "model_DNN.add(Dropout(0.25))\n",
        "model_DNN.add(Dense(1000, activation='relu'))\n",
        "#model_DNN.add(BatchNormalization())\n",
        "model_DNN.add(Dropout(0.25))\n",
        "model_DNN.add(Dense(500, activation='relu'))\n",
        "#model_DNN.add(BatchNormalization())\n",
        "model_DNN.add(Dropout(0.25))\n",
        "model_DNN.add(Dense(7, activation='softmax'))\n",
        "\n",
        "model_DNN.summary()"
      ],
      "metadata": {
        "id": "jQx10JpGcyOL",
        "outputId": "d4d932bb-bed4-4334-c6e3-53bb78a12c24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2304)              5310720   \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 2000)              4610000   \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 2000)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1750)              3501750   \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 1750)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1500)              2626500   \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 1500)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1500)              2251500   \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 1500)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1000)              1501000   \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 500)               500500    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 500)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 7)                 3507      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,306,477\n",
            "Trainable params: 21,306,477\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "u0Oh-GDKc03P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model_DNN.fit(X_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=30,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10)])\n",
        "\n",
        "# Get the output of the model\n",
        "output = model_DNN.predict(X_valid)\n",
        "\n",
        "# Compute the mean and standard deviation of the output\n",
        "#mean = K.mean(output)\n",
        "#std = K.std(output)\n",
        "\n",
        "#print('Mean:', mean)\n",
        "#print('Standard deviation:', std)"
      ],
      "metadata": {
        "id": "evJxxB0zi_9f",
        "outputId": "bd927d41-9b66-48c6-f990-b5acef7d993f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "182/182 [==============================] - 10s 12ms/step - loss: 1.8392 - accuracy: 0.2369 - val_loss: 1.8161 - val_accuracy: 0.2505\n",
            "Epoch 2/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.8126 - accuracy: 0.2505 - val_loss: 1.7814 - val_accuracy: 0.2790\n",
            "Epoch 3/30\n",
            "182/182 [==============================] - 2s 11ms/step - loss: 1.7611 - accuracy: 0.2819 - val_loss: 1.7186 - val_accuracy: 0.3052\n",
            "Epoch 4/30\n",
            "182/182 [==============================] - 2s 12ms/step - loss: 1.7236 - accuracy: 0.3074 - val_loss: 1.7062 - val_accuracy: 0.3164\n",
            "Epoch 5/30\n",
            "182/182 [==============================] - 2s 11ms/step - loss: 1.7008 - accuracy: 0.3219 - val_loss: 1.6813 - val_accuracy: 0.3322\n",
            "Epoch 6/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.6802 - accuracy: 0.3328 - val_loss: 1.6746 - val_accuracy: 0.3334\n",
            "Epoch 7/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.6519 - accuracy: 0.3500 - val_loss: 1.6381 - val_accuracy: 0.3553\n",
            "Epoch 8/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.6353 - accuracy: 0.3578 - val_loss: 1.6271 - val_accuracy: 0.3629\n",
            "Epoch 9/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.6156 - accuracy: 0.3660 - val_loss: 1.6260 - val_accuracy: 0.3605\n",
            "Epoch 10/30\n",
            "182/182 [==============================] - 2s 12ms/step - loss: 1.6038 - accuracy: 0.3702 - val_loss: 1.6315 - val_accuracy: 0.3567\n",
            "Epoch 11/30\n",
            "182/182 [==============================] - 2s 12ms/step - loss: 1.5836 - accuracy: 0.3804 - val_loss: 1.6060 - val_accuracy: 0.3731\n",
            "Epoch 12/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.5708 - accuracy: 0.3861 - val_loss: 1.6011 - val_accuracy: 0.3697\n",
            "Epoch 13/30\n",
            "182/182 [==============================] - 2s 11ms/step - loss: 1.5559 - accuracy: 0.3923 - val_loss: 1.6179 - val_accuracy: 0.3634\n",
            "Epoch 14/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.5419 - accuracy: 0.4002 - val_loss: 1.5853 - val_accuracy: 0.3862\n",
            "Epoch 15/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.5283 - accuracy: 0.4054 - val_loss: 1.6187 - val_accuracy: 0.3784\n",
            "Epoch 16/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.5184 - accuracy: 0.4086 - val_loss: 1.5997 - val_accuracy: 0.3852\n",
            "Epoch 17/30\n",
            "182/182 [==============================] - 2s 12ms/step - loss: 1.4951 - accuracy: 0.4217 - val_loss: 1.6050 - val_accuracy: 0.3803\n",
            "Epoch 18/30\n",
            "182/182 [==============================] - 2s 11ms/step - loss: 1.4843 - accuracy: 0.4278 - val_loss: 1.5767 - val_accuracy: 0.3888\n",
            "Epoch 19/30\n",
            "182/182 [==============================] - 2s 11ms/step - loss: 1.4656 - accuracy: 0.4283 - val_loss: 1.5773 - val_accuracy: 0.3945\n",
            "Epoch 20/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.4455 - accuracy: 0.4453 - val_loss: 1.5609 - val_accuracy: 0.3960\n",
            "Epoch 21/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.4324 - accuracy: 0.4475 - val_loss: 1.5690 - val_accuracy: 0.3936\n",
            "Epoch 22/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.4145 - accuracy: 0.4540 - val_loss: 1.5818 - val_accuracy: 0.3864\n",
            "Epoch 23/30\n",
            "182/182 [==============================] - 2s 11ms/step - loss: 1.4042 - accuracy: 0.4591 - val_loss: 1.5823 - val_accuracy: 0.3960\n",
            "Epoch 24/30\n",
            "182/182 [==============================] - 2s 12ms/step - loss: 1.3747 - accuracy: 0.4746 - val_loss: 1.5805 - val_accuracy: 0.4095\n",
            "Epoch 25/30\n",
            "182/182 [==============================] - 2s 11ms/step - loss: 1.3520 - accuracy: 0.4828 - val_loss: 1.6143 - val_accuracy: 0.3924\n",
            "Epoch 26/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.3400 - accuracy: 0.4890 - val_loss: 1.5956 - val_accuracy: 0.3993\n",
            "Epoch 27/30\n",
            "182/182 [==============================] - 2s 11ms/step - loss: 1.3194 - accuracy: 0.5006 - val_loss: 1.6391 - val_accuracy: 0.3907\n",
            "Epoch 28/30\n",
            "182/182 [==============================] - 2s 10ms/step - loss: 1.2912 - accuracy: 0.5115 - val_loss: 1.6412 - val_accuracy: 0.3862\n",
            "Epoch 29/30\n",
            "182/182 [==============================] - 2s 11ms/step - loss: 1.2723 - accuracy: 0.5136 - val_loss: 1.6082 - val_accuracy: 0.4079\n",
            "Epoch 30/30\n",
            "182/182 [==============================] - 2s 11ms/step - loss: 1.2390 - accuracy: 0.5311 - val_loss: 1.6104 - val_accuracy: 0.4095\n",
            "182/182 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Complex NN Models\n",
        "Algorithms Covered:\n",
        "\n",
        "1. CNN\n",
        "2. DCNN\n",
        "3. Transfer learning "
      ],
      "metadata": {
        "id": "YbNsAwXWdlJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methods: \n",
        "\n",
        "1. So, far from the dataset we have learnt that the dataset is an array of pixels and to make it a numpy array we need to convert it to the float type for better interpretation of the models.\n",
        "\n",
        "2. Now, for the pre-processing of the dataset we decided to Normalize the pixel value by 225 to speed up the CNN model learning.\n",
        "\n",
        "3. We chose a reshaping of 48 x 48 for better fitting and learning. Our random_state is set to 42 while splitting up the data since we are getting good accuracy through it. \n",
        "\n",
        "4. We imported the keras early stopping to reduce the computational power consumed at a early stage. And We are using ADAM as optimizer to modify the attributes of the CNN.\n",
        "\n",
        "6. We are also using one hot encoding categorically to generate target labels.\n",
        "\n",
        "5. Also, we have observed a a minor increase in the model accuracy with Data Augmentation. This can be explained by interpreting that the model is learning more when more range of data is provided, however in some cases the augmented data is making the task more difficult for the NN models."
      ],
      "metadata": {
        "id": "6R4hoVDEdysR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "kxjiSdJld0ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model:\n",
        "\n",
        "The 1st model implemented by us is a CNN model, We have adapted ADAM optimizer with 0.01 as learning rate with cross-entropy and accuracy as the evaluation metric. \n",
        "\n",
        "Four different droupout layers are added to reduce overfitting and multiple convolution layers of depth 3 and different sizes are implemented with max pooling layer to imporve the feature mapping. Our Data Augmentation consists of width and height shifting, zooming and flipping. \n",
        "\n",
        "We have observed that the validation loss was not improving at a certain point and also implemented reduction learning rate by factor 0.1 after 5 epochs and have implemented early stopping if the model validation loss doesn't improve after 10 epochs.\n",
        "\n",
        "Lastly, we have used a batch size of 32 for dividing the training set.\n"
      ],
      "metadata": {
        "id": "NDjlb_U77Rek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n"
      ],
      "metadata": {
        "id": "fMFMpwguicSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/my_emotion_train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/my_emotion_test.csv')\n",
        "\n",
        "# Convert the \"pixels\" column to a numpy array\n",
        "X = np.array([np.array(pixel.split(' ')).astype('float32') for pixel in train_df['pixels']])\n",
        "y = train_df['emotion']\n",
        "\n",
        "# Normalize the pixel values\n",
        "X /= 255.0\n",
        "\n",
        "# Reshape the data to fit the CNN input shape\n",
        "X = X.reshape(-1, 48, 48, 1)\n",
        "\n",
        "# One-hot encode the target labels\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n"
      ],
      "metadata": {
        "id": "4Rr1BLzBid7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(48, 48, 1)),\n",
        "    Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(7, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "LZ-64HQzif0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer with a higher learning rate\n",
        "opt = Adam(lr=0.01)\n",
        "\n",
        "# Compile the model with the optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n"
      ],
      "metadata": {
        "id": "Ia3ox1X4ihwL",
        "outputId": "148a3291-a0b3-403a-dd22-c826eecde53a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=1,width_shift_range=0.03,\n",
        "                                  height_shift_range=0.03,shear_range=0.03,\n",
        "                                  zoom_range=0.02,horizontal_flip=False,)\n",
        "train_datagen.fit(X_train)\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32 \n",
        "epochs = 100\n",
        "optims = [optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)]\n"
      ],
      "metadata": {
        "id": "I4pa0DHaijiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                              validation_data=(X_test, y_test),\n",
        "                              steps_per_epoch=len(X_train) / batch_size,\n",
        "                              epochs=epochs,\n",
        "                              use_multiprocessing=True,\n",
        "                              callbacks=[reduce_lr, early_stopping])\n"
      ],
      "metadata": {
        "id": "K_Xvvwn5isTb",
        "outputId": "6abd369a-7811-4b46-ae8d-5acb0b6fb96b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-f7a64aad1869>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "770/770 [==============================] - 27s 23ms/step - loss: 1.8147 - accuracy: 0.2501 - val_loss: 1.7497 - val_accuracy: 0.2674 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.7087 - accuracy: 0.3116 - val_loss: 1.6624 - val_accuracy: 0.3577 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "770/770 [==============================] - 19s 24ms/step - loss: 1.6273 - accuracy: 0.3589 - val_loss: 1.4807 - val_accuracy: 0.4246 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "770/770 [==============================] - 17s 23ms/step - loss: 1.5655 - accuracy: 0.3947 - val_loss: 1.5194 - val_accuracy: 0.3998 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.5124 - accuracy: 0.4089 - val_loss: 1.3946 - val_accuracy: 0.4614 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.4709 - accuracy: 0.4319 - val_loss: 1.3541 - val_accuracy: 0.4851 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.4425 - accuracy: 0.4419 - val_loss: 1.4244 - val_accuracy: 0.4434 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "770/770 [==============================] - 19s 24ms/step - loss: 1.4094 - accuracy: 0.4566 - val_loss: 1.3043 - val_accuracy: 0.4913 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.3744 - accuracy: 0.4723 - val_loss: 1.2545 - val_accuracy: 0.5205 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.3484 - accuracy: 0.4839 - val_loss: 1.2891 - val_accuracy: 0.5018 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 1.3348 - accuracy: 0.4902 - val_loss: 1.3035 - val_accuracy: 0.5028 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.3165 - accuracy: 0.4941 - val_loss: 1.2269 - val_accuracy: 0.5278 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 1.2952 - accuracy: 0.5049 - val_loss: 1.1978 - val_accuracy: 0.5372 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "770/770 [==============================] - 18s 22ms/step - loss: 1.2855 - accuracy: 0.5119 - val_loss: 1.1866 - val_accuracy: 0.5432 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "770/770 [==============================] - 18s 24ms/step - loss: 1.2729 - accuracy: 0.5152 - val_loss: 1.1849 - val_accuracy: 0.5494 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 1.2581 - accuracy: 0.5227 - val_loss: 1.2193 - val_accuracy: 0.5299 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.2366 - accuracy: 0.5266 - val_loss: 1.1465 - val_accuracy: 0.5549 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.2357 - accuracy: 0.5301 - val_loss: 1.1414 - val_accuracy: 0.5593 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.2160 - accuracy: 0.5359 - val_loss: 1.1357 - val_accuracy: 0.5715 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "770/770 [==============================] - 18s 24ms/step - loss: 1.2079 - accuracy: 0.5424 - val_loss: 1.1218 - val_accuracy: 0.5770 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.2031 - accuracy: 0.5474 - val_loss: 1.1247 - val_accuracy: 0.5660 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.1829 - accuracy: 0.5547 - val_loss: 1.1031 - val_accuracy: 0.5795 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.1700 - accuracy: 0.5597 - val_loss: 1.1084 - val_accuracy: 0.5811 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.1732 - accuracy: 0.5567 - val_loss: 1.0987 - val_accuracy: 0.5795 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "770/770 [==============================] - 19s 24ms/step - loss: 1.1588 - accuracy: 0.5654 - val_loss: 1.0869 - val_accuracy: 0.5929 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.1487 - accuracy: 0.5707 - val_loss: 1.1080 - val_accuracy: 0.5823 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.1371 - accuracy: 0.5712 - val_loss: 1.0882 - val_accuracy: 0.5864 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.1317 - accuracy: 0.5743 - val_loss: 1.0849 - val_accuracy: 0.5876 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.1383 - accuracy: 0.5734 - val_loss: 1.1200 - val_accuracy: 0.5772 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.1170 - accuracy: 0.5802 - val_loss: 1.0838 - val_accuracy: 0.5938 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "770/770 [==============================] - 18s 24ms/step - loss: 1.1129 - accuracy: 0.5810 - val_loss: 1.0683 - val_accuracy: 0.6021 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.1079 - accuracy: 0.5862 - val_loss: 1.0559 - val_accuracy: 0.6106 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.0912 - accuracy: 0.5920 - val_loss: 1.0598 - val_accuracy: 0.6014 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "770/770 [==============================] - 19s 25ms/step - loss: 1.0910 - accuracy: 0.5903 - val_loss: 1.0522 - val_accuracy: 0.6067 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.0908 - accuracy: 0.5890 - val_loss: 1.0438 - val_accuracy: 0.6117 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.0717 - accuracy: 0.5952 - val_loss: 1.0392 - val_accuracy: 0.6140 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "770/770 [==============================] - 19s 24ms/step - loss: 1.0672 - accuracy: 0.5964 - val_loss: 1.0660 - val_accuracy: 0.6092 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.0632 - accuracy: 0.6017 - val_loss: 1.0498 - val_accuracy: 0.6110 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 1.0672 - accuracy: 0.5974 - val_loss: 1.0737 - val_accuracy: 0.6044 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 1.0592 - accuracy: 0.6010 - val_loss: 1.0470 - val_accuracy: 0.6110 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "770/770 [==============================] - 21s 27ms/step - loss: 1.0380 - accuracy: 0.6107 - val_loss: 1.0404 - val_accuracy: 0.6124 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "770/770 [==============================] - 20s 26ms/step - loss: 1.0035 - accuracy: 0.6265 - val_loss: 1.0161 - val_accuracy: 0.6179 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "770/770 [==============================] - 19s 24ms/step - loss: 1.0000 - accuracy: 0.6233 - val_loss: 1.0116 - val_accuracy: 0.6225 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "770/770 [==============================] - 22s 28ms/step - loss: 0.9924 - accuracy: 0.6308 - val_loss: 1.0087 - val_accuracy: 0.6211 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "770/770 [==============================] - 19s 25ms/step - loss: 0.9836 - accuracy: 0.6310 - val_loss: 1.0099 - val_accuracy: 0.6202 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "770/770 [==============================] - 17s 21ms/step - loss: 0.9800 - accuracy: 0.6351 - val_loss: 1.0078 - val_accuracy: 0.6234 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 0.9732 - accuracy: 0.6366 - val_loss: 1.0086 - val_accuracy: 0.6280 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 0.9714 - accuracy: 0.6380 - val_loss: 1.0053 - val_accuracy: 0.6209 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 0.9654 - accuracy: 0.6381 - val_loss: 1.0063 - val_accuracy: 0.6207 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 0.9677 - accuracy: 0.6381 - val_loss: 1.0057 - val_accuracy: 0.6283 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 0.9666 - accuracy: 0.6424 - val_loss: 1.0004 - val_accuracy: 0.6264 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 0.9608 - accuracy: 0.6403 - val_loss: 0.9997 - val_accuracy: 0.6292 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 0.9556 - accuracy: 0.6443 - val_loss: 1.0010 - val_accuracy: 0.6241 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 0.9566 - accuracy: 0.6415 - val_loss: 1.0022 - val_accuracy: 0.6264 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "770/770 [==============================] - 23s 30ms/step - loss: 0.9529 - accuracy: 0.6452 - val_loss: 1.0000 - val_accuracy: 0.6294 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "770/770 [==============================] - 19s 25ms/step - loss: 0.9514 - accuracy: 0.6438 - val_loss: 0.9988 - val_accuracy: 0.6283 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 0.9500 - accuracy: 0.6445 - val_loss: 0.9971 - val_accuracy: 0.6306 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 0.9487 - accuracy: 0.6488 - val_loss: 0.9975 - val_accuracy: 0.6303 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 0.9471 - accuracy: 0.6476 - val_loss: 0.9969 - val_accuracy: 0.6306 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "770/770 [==============================] - 17s 22ms/step - loss: 0.9430 - accuracy: 0.6483 - val_loss: 1.0016 - val_accuracy: 0.6294 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "770/770 [==============================] - 17s 23ms/step - loss: 0.9421 - accuracy: 0.6470 - val_loss: 0.9972 - val_accuracy: 0.6320 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 0.9390 - accuracy: 0.6472 - val_loss: 0.9971 - val_accuracy: 0.6271 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "770/770 [==============================] - 17s 23ms/step - loss: 0.9389 - accuracy: 0.6498 - val_loss: 1.0053 - val_accuracy: 0.6283 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 0.9325 - accuracy: 0.6529 - val_loss: 1.0016 - val_accuracy: 0.6287 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 0.9315 - accuracy: 0.6490 - val_loss: 0.9983 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
            "Epoch 66/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 0.9321 - accuracy: 0.6542 - val_loss: 0.9988 - val_accuracy: 0.6333 - lr: 1.0000e-05\n",
            "Epoch 67/100\n",
            "770/770 [==============================] - 19s 24ms/step - loss: 0.9293 - accuracy: 0.6525 - val_loss: 0.9995 - val_accuracy: 0.6331 - lr: 1.0000e-05\n",
            "Epoch 68/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 0.9286 - accuracy: 0.6533 - val_loss: 0.9985 - val_accuracy: 0.6347 - lr: 1.0000e-05\n",
            "Epoch 69/100\n",
            "770/770 [==============================] - 18s 23ms/step - loss: 0.9331 - accuracy: 0.6563 - val_loss: 0.9989 - val_accuracy: 0.6338 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the output of the model\n",
        "output = model.predict(X_test)\n",
        "\n",
        "# Compute the mean and standard deviation of the output\n",
        "#mean = K.mean(output)\n",
        "#std = K.std(output)\n",
        "\n",
        "#print('Mean:', mean)\n",
        "#print('Standard deviation:', std)"
      ],
      "metadata": {
        "id": "Oy3himA0oF2X",
        "outputId": "1d4fd1f7-d8cb-47fe-df15-1de708bf7fa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136/136 [==============================] - 1s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "rFMWeprais8b",
        "outputId": "c5cd8157-440a-45e9-d478-e691b53a442f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.6337931156158447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.DCNN (with improvements in NN Layers)\n",
        "\n",
        "We have used DCNN using Keras library. Likewise the DCNN model is very similar to CNN but with a large number of hidden layers and combination of doupout layers to restrict overfitting. The DCNN model also consists of maxpooling layer to result a pooled feature map. And lastly for converting the semi-structured data to a relatable data we are using flatten.\n",
        "\n",
        "Also, early stopping and data augmentation is implemented the same way as the CNN model. Learning rate of 0.001, batch size of 32 and epoch of 100 is implemented in this model to improve the accuracy.\n",
        "\n",
        "This DCCN is one of our best models that improves the accuracy by some extent. \n"
      ],
      "metadata": {
        "id": "d4UZFGX5e39m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout, BatchNormalization, LeakyReLU, Activation\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "kAtBbWjSe8E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link='/content/drive/MyDrive/my_emotion_train.csv'"
      ],
      "metadata": {
        "id": "bEWqpn06f-hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(link)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "OSzsXmmvgBnL",
        "outputId": "eb10b29c-e996-4d63-da1a-442c506cbcc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id  emotion                                             pixels\n",
              "0   9415        6  29 16 18 18 18 20 19 18 17 17 17 18 17 18 17 1...\n",
              "1  19109        3  126 154 167 181 188 194 195 194 196 195 198 20...\n",
              "2  21523        2  169 220 218 208 184 144 72 73 143 183 203 210 ...\n",
              "3   2076        3  60 64 72 80 83 83 80 82 89 106 114 125 125 127...\n",
              "4  13957        3  174 148 121 97 78 70 62 57 54 54 42 58 40 64 1..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8eb3b1c2-6b03-4e73-b56a-cb62c33eb15c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9415</td>\n",
              "      <td>6</td>\n",
              "      <td>29 16 18 18 18 20 19 18 17 17 17 18 17 18 17 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19109</td>\n",
              "      <td>3</td>\n",
              "      <td>126 154 167 181 188 194 195 194 196 195 198 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21523</td>\n",
              "      <td>2</td>\n",
              "      <td>169 220 218 208 184 144 72 73 143 183 203 210 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2076</td>\n",
              "      <td>3</td>\n",
              "      <td>60 64 72 80 83 83 80 82 89 106 114 125 125 127...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13957</td>\n",
              "      <td>3</td>\n",
              "      <td>174 148 121 97 78 70 62 57 54 54 42 58 40 64 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8eb3b1c2-6b03-4e73-b56a-cb62c33eb15c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8eb3b1c2-6b03-4e73-b56a-cb62c33eb15c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8eb3b1c2-6b03-4e73-b56a-cb62c33eb15c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "R_WfHvcPgE3E",
        "outputId": "d4fe42a9-4994-451b-b5fc-24d89df2f9a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['emotion'].unique()"
      ],
      "metadata": {
        "id": "6sheciGbgHnx",
        "outputId": "66c3a1d7-d027-42ef-d920-af064f651021",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 3, 2, 4, 5, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_label={0:'Anger', 1:'Disgust', 2:'Fear', 3: 'Happiness', 4: 'Sadness', 5: 'Surprise', 6:'Neutral'}"
      ],
      "metadata": {
        "id": "CeaAO35DgLsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.emotion.value_counts()"
      ],
      "metadata": {
        "id": "IZc6AWwwgNa8",
        "outputId": "96333a48-4b36-493a-b25f-a6d734de7f5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    7289\n",
              "6    4992\n",
              "4    4942\n",
              "2    4138\n",
              "0    3993\n",
              "5    3206\n",
              "1     440\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_array = df.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48,48, 1).astype('float32'))\n",
        "img_array = np.stack(img_array, axis=0)"
      ],
      "metadata": {
        "id": "qbg1ywVhgT71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "img_labels = le.fit_transform(df.emotion)\n",
        "img_labels = np_utils.to_categorical(img_labels)\n",
        "img_labels.shape"
      ],
      "metadata": {
        "id": "hEPje9AjgXfp",
        "outputId": "f490d1b4-c889-40b3-8e04-f9bb1a65dba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29000, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(le_name_mapping)"
      ],
      "metadata": {
        "id": "urBrWdUWgbD-",
        "outputId": "28fae640-2152-4615-8d41-0bd5516bc3b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(img_array, img_labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "QtBNWkPfgeB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width = X_train.shape[1]\n",
        "img_height = X_train.shape[2]\n",
        "img_depth = X_train.shape[3]\n",
        "num_classes = y_train.shape[1]"
      ],
      "metadata": {
        "id": "CciSCbpSggja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train / 255\n",
        "X_valid = X_valid / 255"
      ],
      "metadata": {
        "id": "6LGRN1ESgi2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_net(optim):\n",
        "   \n",
        "    net = Sequential(name='DCNN')\n",
        "\n",
        "    net.add(Conv2D(filters=64,kernel_size=(5,5),input_shape=(img_width, img_height, img_depth),activation='elu',padding='same',name='conv2d_1'))\n",
        "   \n",
        "    net.add(BatchNormalization(name='batchnorm_1'))\n",
        "    \n",
        "    net.add(Conv2D(filters=64,kernel_size=(5,5),activation='elu',padding='same',name='conv2d_2'))\n",
        "    \n",
        "    net.add(BatchNormalization(name='batchnorm_2'))\n",
        "    \n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n",
        "    \n",
        "    net.add(Dropout(0.4, name='dropout_1'))\n",
        "\n",
        "    net.add(Conv2D(filters=128,kernel_size=(3,3),activation='elu',padding='same',name='conv2d_3'))\n",
        "    \n",
        "    net.add(BatchNormalization(name='batchnorm_3'))\n",
        "    \n",
        "    net.add(Conv2D(filters=128,kernel_size=(3,3),activation='elu',padding='same',name='conv2d_4'))\n",
        "    \n",
        "    net.add(BatchNormalization(name='batchnorm_4'))\n",
        "\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n",
        "    \n",
        "    net.add(Dropout(0.4, name='dropout_2'))\n",
        "\n",
        "    net.add(Conv2D(filters=256,kernel_size=(3,3),activation='elu',padding='same',name='conv2d_5'))\n",
        "    \n",
        "    net.add(BatchNormalization(name='batchnorm_5'))\n",
        "\n",
        "    net.add(Conv2D(filters=256,kernel_size=(3,3),activation='elu',padding='same',name='conv2d_6'))\n",
        "    \n",
        "    net.add(BatchNormalization(name='batchnorm_6'))\n",
        "\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n",
        "    \n",
        "    net.add(Dropout(0.4, name='dropout_3'))\n",
        "\n",
        "    net.add(Conv2D(filters=256,kernel_size=(3,3),activation='elu',padding='same',name='conv2d_7'))\n",
        "    \n",
        "    net.add(BatchNormalization(name='batchnorm_7'))\n",
        "\n",
        "    net.add(Conv2D(filters=256,kernel_size=(3,3),activation='elu',padding='same',name='conv2d_8'))\n",
        "    \n",
        "    net.add(BatchNormalization(name='batchnorm_8'))\n",
        "    \n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_4'))\n",
        "    \n",
        "    net.add(Dropout(0.5, name='dropout_4'))\n",
        "\n",
        "    net.add(Flatten(name='flatten'))\n",
        "\n",
        "    net.add(Dense(128,activation='relu',name='dense_1'))\n",
        "\n",
        "    net.add(BatchNormalization(name='batchnorm_9'))\n",
        "    \n",
        "    net.add(Dropout(0.6, name='dropout_5'))\n",
        "    \n",
        "    net.add(Dense(num_classes,activation='softmax',name='out_layer'))\n",
        "\n",
        "    net.compile(loss='categorical_crossentropy',optimizer=optim,metrics=['accuracy'])\n",
        "\n",
        "    net.summary()\n",
        "\n",
        "    return net "
      ],
      "metadata": {
        "id": "MmzCtrWfglFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy',min_delta=0.000005,\n",
        "                               patience=15,verbose=1,restore_best_weights=True,)\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy',factor=0.5,patience=10,min_lr=1e-7,verbose=1,)\n",
        "\n",
        "callbacks = [ early_stopping,lr_scheduler,]"
      ],
      "metadata": {
        "id": "JPU9InqTgnRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=15,width_shift_range=0.15,\n",
        "                                  height_shift_range=0.10,shear_range=0.15,\n",
        "                                  zoom_range=0.10,horizontal_flip=True,)\n",
        "train_datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "2NU7aupLgwSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 \n",
        "epochs = 100\n",
        "optims = [optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\n",
        "          optimizers.Adam(0.001),]\n",
        "\n",
        "model = build_net(optims[1]) \n",
        "history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                              validation_data=(X_valid, y_valid),\n",
        "                             steps_per_epoch=len(X_train) / batch_size,\n",
        "                              epochs=epochs,callbacks=callbacks,use_multiprocessing=True)"
      ],
      "metadata": {
        "id": "sfRTkm0ngqPS",
        "outputId": "ca512499-9fcf-44b6-82b6-6529e3e2567e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"DCNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 48, 48, 64)        1664      \n",
            "                                                                 \n",
            " batchnorm_1 (BatchNormaliza  (None, 48, 48, 64)       256       \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 48, 48, 64)        102464    \n",
            "                                                                 \n",
            " batchnorm_2 (BatchNormaliza  (None, 48, 48, 64)       256       \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " maxpool2d_1 (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " batchnorm_3 (BatchNormaliza  (None, 24, 24, 128)      512       \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " batchnorm_4 (BatchNormaliza  (None, 24, 24, 128)      512       \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " maxpool2d_2 (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " batchnorm_5 (BatchNormaliza  (None, 12, 12, 256)      1024      \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batchnorm_6 (BatchNormaliza  (None, 12, 12, 256)      1024      \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " maxpool2d_3 (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batchnorm_7 (BatchNormaliza  (None, 6, 6, 256)        1024      \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batchnorm_8 (BatchNormaliza  (None, 6, 6, 256)        1024      \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " maxpool2d_4 (MaxPooling2D)  (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               295040    \n",
            "                                                                 \n",
            " batchnorm_9 (BatchNormaliza  (None, 128)              512       \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,693,063\n",
            "Trainable params: 2,689,991\n",
            "Non-trainable params: 3,072\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-74-3c282f8e6489>:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "725/725 [==============================] - 40s 42ms/step - loss: 2.2359 - accuracy: 0.2038 - val_loss: 1.7646 - val_accuracy: 0.2759 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "725/725 [==============================] - 30s 41ms/step - loss: 1.7648 - accuracy: 0.2952 - val_loss: 1.6228 - val_accuracy: 0.3622 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 1.6059 - accuracy: 0.3724 - val_loss: 1.4725 - val_accuracy: 0.4241 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 1.4747 - accuracy: 0.4287 - val_loss: 1.3782 - val_accuracy: 0.4678 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "725/725 [==============================] - 27s 38ms/step - loss: 1.3909 - accuracy: 0.4665 - val_loss: 1.2360 - val_accuracy: 0.5271 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "725/725 [==============================] - 34s 46ms/step - loss: 1.3417 - accuracy: 0.4898 - val_loss: 1.2129 - val_accuracy: 0.5367 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 1.2884 - accuracy: 0.5119 - val_loss: 1.2827 - val_accuracy: 0.5022 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 1.2521 - accuracy: 0.5278 - val_loss: 1.2356 - val_accuracy: 0.5316 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "725/725 [==============================] - 30s 41ms/step - loss: 1.2279 - accuracy: 0.5403 - val_loss: 1.1887 - val_accuracy: 0.5464 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 1.1898 - accuracy: 0.5548 - val_loss: 1.1112 - val_accuracy: 0.5778 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "725/725 [==============================] - 30s 41ms/step - loss: 1.1738 - accuracy: 0.5628 - val_loss: 1.1412 - val_accuracy: 0.5717 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 1.1441 - accuracy: 0.5766 - val_loss: 1.0870 - val_accuracy: 0.5857 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 1.1342 - accuracy: 0.5789 - val_loss: 1.3653 - val_accuracy: 0.4722 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 1.1151 - accuracy: 0.5864 - val_loss: 1.0686 - val_accuracy: 0.6019 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 1.1094 - accuracy: 0.5907 - val_loss: 1.0544 - val_accuracy: 0.6050 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "725/725 [==============================] - 27s 38ms/step - loss: 1.0890 - accuracy: 0.5967 - val_loss: 1.0595 - val_accuracy: 0.6038 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "725/725 [==============================] - 34s 47ms/step - loss: 1.0747 - accuracy: 0.6023 - val_loss: 1.0046 - val_accuracy: 0.6233 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "725/725 [==============================] - 27s 38ms/step - loss: 1.0604 - accuracy: 0.6085 - val_loss: 1.0060 - val_accuracy: 0.6279 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 1.0543 - accuracy: 0.6105 - val_loss: 1.0029 - val_accuracy: 0.6255 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "725/725 [==============================] - 31s 42ms/step - loss: 1.0402 - accuracy: 0.6117 - val_loss: 1.0090 - val_accuracy: 0.6264 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "725/725 [==============================] - 30s 42ms/step - loss: 1.0248 - accuracy: 0.6225 - val_loss: 1.0003 - val_accuracy: 0.6319 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 1.0222 - accuracy: 0.6175 - val_loss: 1.0223 - val_accuracy: 0.6178 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 1.0122 - accuracy: 0.6300 - val_loss: 0.9732 - val_accuracy: 0.6419 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.9987 - accuracy: 0.6320 - val_loss: 0.9973 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.9929 - accuracy: 0.6323 - val_loss: 1.0328 - val_accuracy: 0.6245 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "725/725 [==============================] - 29s 40ms/step - loss: 0.9896 - accuracy: 0.6373 - val_loss: 0.9388 - val_accuracy: 0.6605 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "725/725 [==============================] - 29s 40ms/step - loss: 0.9830 - accuracy: 0.6389 - val_loss: 0.9792 - val_accuracy: 0.6397 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "725/725 [==============================] - 30s 42ms/step - loss: 0.9661 - accuracy: 0.6408 - val_loss: 0.9607 - val_accuracy: 0.6419 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "725/725 [==============================] - 31s 43ms/step - loss: 0.9664 - accuracy: 0.6432 - val_loss: 0.9758 - val_accuracy: 0.6409 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.9501 - accuracy: 0.6492 - val_loss: 0.9942 - val_accuracy: 0.6386 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.9455 - accuracy: 0.6548 - val_loss: 0.9637 - val_accuracy: 0.6505 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.9468 - accuracy: 0.6489 - val_loss: 0.9614 - val_accuracy: 0.6502 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.9383 - accuracy: 0.6562 - val_loss: 0.9624 - val_accuracy: 0.6597 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.9315 - accuracy: 0.6605 - val_loss: 0.9261 - val_accuracy: 0.6634 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.9174 - accuracy: 0.6617 - val_loss: 0.9468 - val_accuracy: 0.6564 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.9132 - accuracy: 0.6672 - val_loss: 0.9456 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.9126 - accuracy: 0.6649 - val_loss: 0.9484 - val_accuracy: 0.6657 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "725/725 [==============================] - 31s 43ms/step - loss: 0.8955 - accuracy: 0.6730 - val_loss: 0.9501 - val_accuracy: 0.6555 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "725/725 [==============================] - 30s 41ms/step - loss: 0.8961 - accuracy: 0.6715 - val_loss: 0.9335 - val_accuracy: 0.6634 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.9028 - accuracy: 0.6724 - val_loss: 0.9542 - val_accuracy: 0.6557 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.8872 - accuracy: 0.6772 - val_loss: 0.9461 - val_accuracy: 0.6571 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "725/725 [==============================] - 31s 42ms/step - loss: 0.8846 - accuracy: 0.6738 - val_loss: 0.9367 - val_accuracy: 0.6616 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "725/725 [==============================] - 29s 39ms/step - loss: 0.8803 - accuracy: 0.6774 - val_loss: 0.9478 - val_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "725/725 [==============================] - 30s 41ms/step - loss: 0.8698 - accuracy: 0.6863 - val_loss: 0.9487 - val_accuracy: 0.6607 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.8757 - accuracy: 0.6776 - val_loss: 0.9367 - val_accuracy: 0.6609 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.8611 - accuracy: 0.6878 - val_loss: 0.9792 - val_accuracy: 0.6481 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "725/725 [==============================] - 31s 42ms/step - loss: 0.8573 - accuracy: 0.6879 - val_loss: 0.9338 - val_accuracy: 0.6633 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.8512 - accuracy: 0.6849 - val_loss: 0.9584 - val_accuracy: 0.6648 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "725/725 [==============================] - 30s 41ms/step - loss: 0.8489 - accuracy: 0.6907 - val_loss: 0.9449 - val_accuracy: 0.6591 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.8501 - accuracy: 0.6899 - val_loss: 0.9569 - val_accuracy: 0.6574 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "725/725 [==============================] - 29s 39ms/step - loss: 0.8443 - accuracy: 0.6956 - val_loss: 0.9507 - val_accuracy: 0.6688 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.8317 - accuracy: 0.6935 - val_loss: 0.9480 - val_accuracy: 0.6633 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "724/725 [============================>.] - ETA: 0s - loss: 0.8307 - accuracy: 0.6978\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.8305 - accuracy: 0.6979 - val_loss: 0.9459 - val_accuracy: 0.6636 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.8093 - accuracy: 0.7054 - val_loss: 0.9298 - val_accuracy: 0.6712 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.7921 - accuracy: 0.7127 - val_loss: 0.9196 - val_accuracy: 0.6736 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.7908 - accuracy: 0.7148 - val_loss: 0.9300 - val_accuracy: 0.6788 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.7825 - accuracy: 0.7141 - val_loss: 0.9502 - val_accuracy: 0.6707 - lr: 5.0000e-04\n",
            "Epoch 58/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.7649 - accuracy: 0.7228 - val_loss: 0.9294 - val_accuracy: 0.6734 - lr: 5.0000e-04\n",
            "Epoch 59/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.7710 - accuracy: 0.7209 - val_loss: 0.9271 - val_accuracy: 0.6703 - lr: 5.0000e-04\n",
            "Epoch 60/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.7662 - accuracy: 0.7226 - val_loss: 0.9270 - val_accuracy: 0.6771 - lr: 5.0000e-04\n",
            "Epoch 61/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.7609 - accuracy: 0.7237 - val_loss: 0.9293 - val_accuracy: 0.6776 - lr: 5.0000e-04\n",
            "Epoch 62/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.7555 - accuracy: 0.7271 - val_loss: 0.9372 - val_accuracy: 0.6803 - lr: 5.0000e-04\n",
            "Epoch 63/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.7541 - accuracy: 0.7243 - val_loss: 0.9260 - val_accuracy: 0.6781 - lr: 5.0000e-04\n",
            "Epoch 64/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.7471 - accuracy: 0.7333 - val_loss: 0.9230 - val_accuracy: 0.6772 - lr: 5.0000e-04\n",
            "Epoch 65/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.7412 - accuracy: 0.7292 - val_loss: 0.9301 - val_accuracy: 0.6776 - lr: 5.0000e-04\n",
            "Epoch 66/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.7468 - accuracy: 0.7294 - val_loss: 0.9467 - val_accuracy: 0.6716 - lr: 5.0000e-04\n",
            "Epoch 67/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.7380 - accuracy: 0.7309 - val_loss: 0.9502 - val_accuracy: 0.6719 - lr: 5.0000e-04\n",
            "Epoch 68/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.7386 - accuracy: 0.7333 - val_loss: 0.9503 - val_accuracy: 0.6800 - lr: 5.0000e-04\n",
            "Epoch 69/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.7259 - accuracy: 0.7362 - val_loss: 0.9358 - val_accuracy: 0.6798 - lr: 5.0000e-04\n",
            "Epoch 70/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.7289 - accuracy: 0.7341 - val_loss: 0.9331 - val_accuracy: 0.6743 - lr: 5.0000e-04\n",
            "Epoch 71/100\n",
            "725/725 [==============================] - 27s 38ms/step - loss: 0.7250 - accuracy: 0.7362 - val_loss: 0.9511 - val_accuracy: 0.6750 - lr: 5.0000e-04\n",
            "Epoch 72/100\n",
            "725/725 [==============================] - ETA: 0s - loss: 0.7259 - accuracy: 0.7392\n",
            "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.7259 - accuracy: 0.7392 - val_loss: 0.9494 - val_accuracy: 0.6736 - lr: 5.0000e-04\n",
            "Epoch 73/100\n",
            "725/725 [==============================] - 29s 40ms/step - loss: 0.7072 - accuracy: 0.7453 - val_loss: 0.9434 - val_accuracy: 0.6766 - lr: 2.5000e-04\n",
            "Epoch 74/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.6963 - accuracy: 0.7480 - val_loss: 0.9465 - val_accuracy: 0.6781 - lr: 2.5000e-04\n",
            "Epoch 75/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.6903 - accuracy: 0.7509 - val_loss: 0.9547 - val_accuracy: 0.6757 - lr: 2.5000e-04\n",
            "Epoch 76/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.6907 - accuracy: 0.7497 - val_loss: 0.9524 - val_accuracy: 0.6778 - lr: 2.5000e-04\n",
            "Epoch 77/100\n",
            "725/725 [==============================] - 29s 39ms/step - loss: 0.6886 - accuracy: 0.7504 - val_loss: 0.9434 - val_accuracy: 0.6840 - lr: 2.5000e-04\n",
            "Epoch 78/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.6852 - accuracy: 0.7525 - val_loss: 0.9698 - val_accuracy: 0.6769 - lr: 2.5000e-04\n",
            "Epoch 79/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.6909 - accuracy: 0.7523 - val_loss: 0.9440 - val_accuracy: 0.6784 - lr: 2.5000e-04\n",
            "Epoch 80/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.6840 - accuracy: 0.7513 - val_loss: 0.9431 - val_accuracy: 0.6793 - lr: 2.5000e-04\n",
            "Epoch 81/100\n",
            "725/725 [==============================] - 27s 38ms/step - loss: 0.6792 - accuracy: 0.7573 - val_loss: 0.9377 - val_accuracy: 0.6800 - lr: 2.5000e-04\n",
            "Epoch 82/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.6736 - accuracy: 0.7575 - val_loss: 0.9346 - val_accuracy: 0.6812 - lr: 2.5000e-04\n",
            "Epoch 83/100\n",
            "725/725 [==============================] - 27s 38ms/step - loss: 0.6730 - accuracy: 0.7578 - val_loss: 0.9564 - val_accuracy: 0.6809 - lr: 2.5000e-04\n",
            "Epoch 84/100\n",
            "725/725 [==============================] - 29s 39ms/step - loss: 0.6708 - accuracy: 0.7566 - val_loss: 0.9461 - val_accuracy: 0.6816 - lr: 2.5000e-04\n",
            "Epoch 85/100\n",
            "725/725 [==============================] - 29s 40ms/step - loss: 0.6744 - accuracy: 0.7588 - val_loss: 0.9559 - val_accuracy: 0.6845 - lr: 2.5000e-04\n",
            "Epoch 86/100\n",
            "725/725 [==============================] - 30s 42ms/step - loss: 0.6621 - accuracy: 0.7606 - val_loss: 0.9560 - val_accuracy: 0.6778 - lr: 2.5000e-04\n",
            "Epoch 87/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.6578 - accuracy: 0.7627 - val_loss: 0.9490 - val_accuracy: 0.6840 - lr: 2.5000e-04\n",
            "Epoch 88/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.6591 - accuracy: 0.7603 - val_loss: 0.9578 - val_accuracy: 0.6822 - lr: 2.5000e-04\n",
            "Epoch 89/100\n",
            "725/725 [==============================] - 28s 39ms/step - loss: 0.6564 - accuracy: 0.7629 - val_loss: 0.9596 - val_accuracy: 0.6836 - lr: 2.5000e-04\n",
            "Epoch 90/100\n",
            "725/725 [==============================] - 30s 42ms/step - loss: 0.6669 - accuracy: 0.7604 - val_loss: 0.9446 - val_accuracy: 0.6828 - lr: 2.5000e-04\n",
            "Epoch 91/100\n",
            "725/725 [==============================] - 29s 40ms/step - loss: 0.6606 - accuracy: 0.7628 - val_loss: 0.9475 - val_accuracy: 0.6831 - lr: 2.5000e-04\n",
            "Epoch 92/100\n",
            "725/725 [==============================] - 29s 40ms/step - loss: 0.6563 - accuracy: 0.7658 - val_loss: 0.9585 - val_accuracy: 0.6793 - lr: 2.5000e-04\n",
            "Epoch 93/100\n",
            "725/725 [==============================] - 29s 39ms/step - loss: 0.6511 - accuracy: 0.7648 - val_loss: 0.9569 - val_accuracy: 0.6816 - lr: 2.5000e-04\n",
            "Epoch 94/100\n",
            "725/725 [==============================] - 29s 40ms/step - loss: 0.6565 - accuracy: 0.7649 - val_loss: 0.9563 - val_accuracy: 0.6834 - lr: 2.5000e-04\n",
            "Epoch 95/100\n",
            "724/725 [============================>.] - ETA: 0s - loss: 0.6531 - accuracy: 0.7641\n",
            "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "725/725 [==============================] - 29s 40ms/step - loss: 0.6530 - accuracy: 0.7642 - val_loss: 0.9601 - val_accuracy: 0.6778 - lr: 2.5000e-04\n",
            "Epoch 96/100\n",
            "725/725 [==============================] - 29s 40ms/step - loss: 0.6380 - accuracy: 0.7694 - val_loss: 0.9614 - val_accuracy: 0.6807 - lr: 1.2500e-04\n",
            "Epoch 97/100\n",
            "725/725 [==============================] - 29s 39ms/step - loss: 0.6390 - accuracy: 0.7690 - val_loss: 0.9636 - val_accuracy: 0.6824 - lr: 1.2500e-04\n",
            "Epoch 98/100\n",
            "725/725 [==============================] - 27s 37ms/step - loss: 0.6342 - accuracy: 0.7713 - val_loss: 0.9619 - val_accuracy: 0.6871 - lr: 1.2500e-04\n",
            "Epoch 99/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.6402 - accuracy: 0.7669 - val_loss: 0.9563 - val_accuracy: 0.6843 - lr: 1.2500e-04\n",
            "Epoch 100/100\n",
            "725/725 [==============================] - 28s 38ms/step - loss: 0.6305 - accuracy: 0.7706 - val_loss: 0.9614 - val_accuracy: 0.6834 - lr: 1.2500e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the output of the model\n",
        "output = model.predict(X_valid)\n",
        "\n",
        "# Compute the mean and standard deviation of the output\n",
        "#mean = K.mean(output)\n",
        "#std = K.std(output)\n",
        "\n",
        "#print('Mean:', mean)\n",
        "#print('Standard deviation:', std)"
      ],
      "metadata": {
        "id": "GtONkVexoQR5",
        "outputId": "c1889fd5-76f9-4c44-f8bc-3d14c97b4557",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "182/182 [==============================] - 2s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(X_valid, y_valid, verbose=0)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "-3wYbzi4iEYA",
        "outputId": "cff3aa4f-6318-4ef6-a041-99cac2472db4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.6834482550621033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Transfer Learning (MobileNet)\n",
        "\n",
        "For the last part of the complex NN model we have implemented the ModelNet model to try transfer learning performances. We chose this model to include as out of most transfer learning models the MobileNet was performing decently. \n",
        "\n",
        "The MobileNetV2 model is used as the tail and we have added the extra layers of head to customize according to our database. We have induced data augmentation for this part such as flipping and rotation to provide extra dataset. We have also implemented the ModelCheck callback to save the best weights for optimal performance. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6zIqjSdig7Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import keras.backend as K"
      ],
      "metadata": {
        "id": "xig8W3-dhGq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/my_emotion_train.csv')\n",
        "\n",
        "X = np.array([np.array(pixel.split(' ')).astype('float32') for pixel in train_df['pixels']])\n",
        "y = train_df['emotion']\n"
      ],
      "metadata": {
        "id": "HCWTMo8yh78B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the pixel values\n",
        "X /= 255.0\n",
        "\n",
        "# Reshape the data to fit the CNN input shape\n",
        "X = X.reshape(-1, 48, 48, 1)\n"
      ],
      "metadata": {
        "id": "EW7tVKzWh_Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data\n",
        "images_train, images_test, labels_train, labels_test = train_test_split(\n",
        "    X, y, test_size=0.20,\n",
        "    random_state=42)\n"
      ],
      "metadata": {
        "id": "q61UEKzUh_0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replicate grayscale channel to create pseudo RGB image\n",
        "images_train = np.repeat(images_train, 3, axis=-1)\n",
        "images_test = np.repeat(images_test, 3, axis=-1)\n",
        "\n",
        "# convert class vectors (integers) to binary class matrix\n",
        "y_train = keras.utils.to_categorical(labels_train, 7)\n",
        "y_test = keras.utils.to_categorical(labels_test, 7)\n"
      ],
      "metadata": {
        "id": "uXwASKfWiCOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base model for transfer learning\n",
        "base_model: keras.Model = keras.applications.MobileNetV2(\n",
        "weights='imagenet', input_shape=(48, 48, 3),\n",
        "include_top=False, pooling='avg')\n",
        "# freeze the base_model so it will not train\n",
        "base_model.trainable = True\n",
        "\n",
        "# create new model\n",
        "model: keras.Model = keras.models.Sequential(\n",
        "    [\n",
        "     # input layer\n",
        "     keras.Input(shape=(48, 48, 3)),\n",
        "     # Augmentation layer - horizontal flip\n",
        "     keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    #  # Augmentation layer - rotation\n",
        "     keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "     # MobileNet model\n",
        "     base_model,\n",
        "     # fully connected layers\n",
        "     keras.layers.Dropout(0.5),\n",
        "     # classification layer\n",
        "     keras.layers.Dense(7, activation='softmax')\n",
        "    ]\n",
        ")\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "3-ThxxJTiD9x",
        "outputId": "29577a58-3aea-4e34-dffc-a5cb1c18f354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " random_flip (RandomFlip)    (None, 48, 48, 3)         0         \n",
            "                                                                 \n",
            " random_rotation (RandomRota  (None, 48, 48, 3)        0         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 7)                 8967      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,266,951\n",
            "Trainable params: 2,232,839\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "     \n",
        "# path to save best model weights\n",
        "checkpoint_file_path = '/content/checkpoint'\n",
        "\n",
        "# model check point to save best model weights\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_file_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "512BH7mCiGLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start training\n",
        "model.fit(\n",
        "    images_train, y_train, epochs=100, validation_split=0.2,\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")\n"
      ],
      "metadata": {
        "id": "QDzJPYXbiHv9",
        "outputId": "a7d59b55-4283-4e7c-ac44-25f0db7d6530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "580/580 [==============================] - 58s 37ms/step - loss: 2.0106 - accuracy: 0.2676 - val_loss: 3.4930 - val_accuracy: 0.2612\n",
            "Epoch 2/100\n",
            "580/580 [==============================] - 18s 31ms/step - loss: 1.7757 - accuracy: 0.3183 - val_loss: 3.5260 - val_accuracy: 0.2037\n",
            "Epoch 3/100\n",
            "580/580 [==============================] - 20s 35ms/step - loss: 1.7154 - accuracy: 0.3345 - val_loss: 2.8023 - val_accuracy: 0.3110\n",
            "Epoch 4/100\n",
            "580/580 [==============================] - 18s 32ms/step - loss: 1.6076 - accuracy: 0.3782 - val_loss: 3.1083 - val_accuracy: 0.3207\n",
            "Epoch 5/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.5476 - accuracy: 0.4017 - val_loss: 2.9889 - val_accuracy: 0.3562\n",
            "Epoch 6/100\n",
            "580/580 [==============================] - 20s 35ms/step - loss: 1.6222 - accuracy: 0.3717 - val_loss: 2.3133 - val_accuracy: 0.2864\n",
            "Epoch 7/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.6492 - accuracy: 0.3626 - val_loss: 2.6686 - val_accuracy: 0.3248\n",
            "Epoch 8/100\n",
            "580/580 [==============================] - 20s 35ms/step - loss: 1.5959 - accuracy: 0.3821 - val_loss: 2.1829 - val_accuracy: 0.4151\n",
            "Epoch 9/100\n",
            "580/580 [==============================] - 19s 32ms/step - loss: 1.5535 - accuracy: 0.4059 - val_loss: 2.8230 - val_accuracy: 0.2989\n",
            "Epoch 10/100\n",
            "580/580 [==============================] - 20s 35ms/step - loss: 1.4978 - accuracy: 0.4321 - val_loss: 2.1356 - val_accuracy: 0.4401\n",
            "Epoch 11/100\n",
            "580/580 [==============================] - 18s 31ms/step - loss: 1.5354 - accuracy: 0.4150 - val_loss: 2.4488 - val_accuracy: 0.4213\n",
            "Epoch 12/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.5381 - accuracy: 0.4127 - val_loss: 4.6079 - val_accuracy: 0.2140\n",
            "Epoch 13/100\n",
            "580/580 [==============================] - 18s 31ms/step - loss: 1.5746 - accuracy: 0.3973 - val_loss: 5.0411 - val_accuracy: 0.2308\n",
            "Epoch 14/100\n",
            "580/580 [==============================] - 18s 31ms/step - loss: 1.4647 - accuracy: 0.4461 - val_loss: 2.6899 - val_accuracy: 0.3530\n",
            "Epoch 15/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.4610 - accuracy: 0.4412 - val_loss: 2.6065 - val_accuracy: 0.3377\n",
            "Epoch 16/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.3901 - accuracy: 0.4732 - val_loss: 1.7656 - val_accuracy: 0.4578\n",
            "Epoch 17/100\n",
            "580/580 [==============================] - 20s 35ms/step - loss: 1.4050 - accuracy: 0.4669 - val_loss: 2.9263 - val_accuracy: 0.3795\n",
            "Epoch 18/100\n",
            "580/580 [==============================] - 19s 34ms/step - loss: 1.5230 - accuracy: 0.4186 - val_loss: 3.8921 - val_accuracy: 0.1978\n",
            "Epoch 19/100\n",
            "580/580 [==============================] - 18s 32ms/step - loss: 1.5891 - accuracy: 0.3835 - val_loss: 4.2096 - val_accuracy: 0.2709\n",
            "Epoch 20/100\n",
            "580/580 [==============================] - 19s 32ms/step - loss: 1.5488 - accuracy: 0.3997 - val_loss: 4.5842 - val_accuracy: 0.3140\n",
            "Epoch 21/100\n",
            "580/580 [==============================] - 18s 32ms/step - loss: 1.4177 - accuracy: 0.4550 - val_loss: 3.0148 - val_accuracy: 0.3468\n",
            "Epoch 22/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.3923 - accuracy: 0.4641 - val_loss: 3.0072 - val_accuracy: 0.2974\n",
            "Epoch 23/100\n",
            "580/580 [==============================] - 19s 32ms/step - loss: 1.3684 - accuracy: 0.4780 - val_loss: 3.2991 - val_accuracy: 0.3569\n",
            "Epoch 24/100\n",
            "580/580 [==============================] - 18s 31ms/step - loss: 1.3542 - accuracy: 0.4824 - val_loss: 4.2992 - val_accuracy: 0.3313\n",
            "Epoch 25/100\n",
            "580/580 [==============================] - 24s 42ms/step - loss: 1.4699 - accuracy: 0.4351 - val_loss: 7.0667 - val_accuracy: 0.3028\n",
            "Epoch 26/100\n",
            "580/580 [==============================] - 24s 41ms/step - loss: 1.4439 - accuracy: 0.4480 - val_loss: 4.5968 - val_accuracy: 0.3119\n",
            "Epoch 27/100\n",
            "580/580 [==============================] - 20s 35ms/step - loss: 1.4364 - accuracy: 0.4543 - val_loss: 3.0439 - val_accuracy: 0.3625\n",
            "Epoch 28/100\n",
            "580/580 [==============================] - 22s 38ms/step - loss: 1.4230 - accuracy: 0.4548 - val_loss: 2.2086 - val_accuracy: 0.3856\n",
            "Epoch 29/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.4062 - accuracy: 0.4581 - val_loss: 2.7194 - val_accuracy: 0.3325\n",
            "Epoch 30/100\n",
            "580/580 [==============================] - 20s 35ms/step - loss: 1.3760 - accuracy: 0.4693 - val_loss: 2.1744 - val_accuracy: 0.4263\n",
            "Epoch 31/100\n",
            "580/580 [==============================] - 24s 42ms/step - loss: 1.3284 - accuracy: 0.4874 - val_loss: 1.8039 - val_accuracy: 0.4388\n",
            "Epoch 32/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.3623 - accuracy: 0.4766 - val_loss: 1.9931 - val_accuracy: 0.4037\n",
            "Epoch 33/100\n",
            "580/580 [==============================] - 20s 35ms/step - loss: 1.3660 - accuracy: 0.4755 - val_loss: 1.6653 - val_accuracy: 0.4293\n",
            "Epoch 34/100\n",
            "580/580 [==============================] - 18s 32ms/step - loss: 1.3661 - accuracy: 0.4753 - val_loss: 2.3647 - val_accuracy: 0.4155\n",
            "Epoch 35/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.3419 - accuracy: 0.4822 - val_loss: 1.7520 - val_accuracy: 0.4638\n",
            "Epoch 36/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.3140 - accuracy: 0.4959 - val_loss: 1.9577 - val_accuracy: 0.4157\n",
            "Epoch 37/100\n",
            "580/580 [==============================] - 21s 36ms/step - loss: 1.2792 - accuracy: 0.5112 - val_loss: 1.5703 - val_accuracy: 0.4918\n",
            "Epoch 38/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.2563 - accuracy: 0.5223 - val_loss: 1.5562 - val_accuracy: 0.4511\n",
            "Epoch 39/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.2455 - accuracy: 0.5268 - val_loss: 1.3201 - val_accuracy: 0.5129\n",
            "Epoch 40/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.2284 - accuracy: 0.5291 - val_loss: 1.4024 - val_accuracy: 0.5121\n",
            "Epoch 41/100\n",
            "580/580 [==============================] - 18s 32ms/step - loss: 1.2164 - accuracy: 0.5362 - val_loss: 1.6507 - val_accuracy: 0.4530\n",
            "Epoch 42/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.2326 - accuracy: 0.5289 - val_loss: 2.4684 - val_accuracy: 0.3938\n",
            "Epoch 43/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.2232 - accuracy: 0.5386 - val_loss: 1.3864 - val_accuracy: 0.5205\n",
            "Epoch 44/100\n",
            "580/580 [==============================] - 27s 47ms/step - loss: 1.1967 - accuracy: 0.5449 - val_loss: 1.4682 - val_accuracy: 0.4834\n",
            "Epoch 45/100\n",
            "580/580 [==============================] - 24s 42ms/step - loss: 1.1851 - accuracy: 0.5497 - val_loss: 1.6203 - val_accuracy: 0.4828\n",
            "Epoch 46/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.1782 - accuracy: 0.5506 - val_loss: 1.5404 - val_accuracy: 0.4957\n",
            "Epoch 47/100\n",
            "580/580 [==============================] - 22s 39ms/step - loss: 1.1941 - accuracy: 0.5450 - val_loss: 1.7918 - val_accuracy: 0.4399\n",
            "Epoch 48/100\n",
            "580/580 [==============================] - 20s 35ms/step - loss: 1.1703 - accuracy: 0.5534 - val_loss: 1.3440 - val_accuracy: 0.5362\n",
            "Epoch 49/100\n",
            "580/580 [==============================] - 23s 39ms/step - loss: 1.1516 - accuracy: 0.5631 - val_loss: 1.5623 - val_accuracy: 0.4948\n",
            "Epoch 50/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.1423 - accuracy: 0.5642 - val_loss: 1.3601 - val_accuracy: 0.5179\n",
            "Epoch 51/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.1341 - accuracy: 0.5692 - val_loss: 1.3767 - val_accuracy: 0.5136\n",
            "Epoch 52/100\n",
            "580/580 [==============================] - 20s 35ms/step - loss: 1.1259 - accuracy: 0.5696 - val_loss: 1.4199 - val_accuracy: 0.5532\n",
            "Epoch 53/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.1123 - accuracy: 0.5789 - val_loss: 1.4492 - val_accuracy: 0.5239\n",
            "Epoch 54/100\n",
            "580/580 [==============================] - 19s 32ms/step - loss: 1.1093 - accuracy: 0.5788 - val_loss: 1.5507 - val_accuracy: 0.4966\n",
            "Epoch 55/100\n",
            "580/580 [==============================] - 21s 36ms/step - loss: 1.1017 - accuracy: 0.5811 - val_loss: 2.0652 - val_accuracy: 0.4116\n",
            "Epoch 56/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.0915 - accuracy: 0.5855 - val_loss: 1.5886 - val_accuracy: 0.4989\n",
            "Epoch 57/100\n",
            "580/580 [==============================] - 20s 35ms/step - loss: 1.0848 - accuracy: 0.5895 - val_loss: 1.4392 - val_accuracy: 0.5328\n",
            "Epoch 58/100\n",
            "580/580 [==============================] - 21s 35ms/step - loss: 1.0845 - accuracy: 0.5895 - val_loss: 1.2696 - val_accuracy: 0.5703\n",
            "Epoch 59/100\n",
            "580/580 [==============================] - 21s 36ms/step - loss: 1.0760 - accuracy: 0.5902 - val_loss: 1.4004 - val_accuracy: 0.5151\n",
            "Epoch 60/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.0716 - accuracy: 0.5952 - val_loss: 1.4805 - val_accuracy: 0.5276\n",
            "Epoch 61/100\n",
            "580/580 [==============================] - 22s 38ms/step - loss: 1.0641 - accuracy: 0.5988 - val_loss: 1.3318 - val_accuracy: 0.5716\n",
            "Epoch 62/100\n",
            "580/580 [==============================] - 21s 37ms/step - loss: 1.0618 - accuracy: 0.5982 - val_loss: 1.4924 - val_accuracy: 0.5399\n",
            "Epoch 63/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.0516 - accuracy: 0.5997 - val_loss: 1.5271 - val_accuracy: 0.5108\n",
            "Epoch 64/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.0380 - accuracy: 0.6062 - val_loss: 1.5624 - val_accuracy: 0.4860\n",
            "Epoch 65/100\n",
            "580/580 [==============================] - 19s 32ms/step - loss: 1.0394 - accuracy: 0.6018 - val_loss: 1.3589 - val_accuracy: 0.5392\n",
            "Epoch 66/100\n",
            "580/580 [==============================] - 21s 36ms/step - loss: 1.0326 - accuracy: 0.6092 - val_loss: 1.3717 - val_accuracy: 0.5356\n",
            "Epoch 67/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 1.0331 - accuracy: 0.6084 - val_loss: 1.4309 - val_accuracy: 0.5254\n",
            "Epoch 68/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.0238 - accuracy: 0.6154 - val_loss: 1.4952 - val_accuracy: 0.5030\n",
            "Epoch 69/100\n",
            "580/580 [==============================] - 19s 32ms/step - loss: 1.0149 - accuracy: 0.6190 - val_loss: 1.3221 - val_accuracy: 0.5315\n",
            "Epoch 70/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 1.0162 - accuracy: 0.6175 - val_loss: 1.5759 - val_accuracy: 0.4804\n",
            "Epoch 71/100\n",
            "580/580 [==============================] - 19s 32ms/step - loss: 1.0085 - accuracy: 0.6205 - val_loss: 1.2694 - val_accuracy: 0.5472\n",
            "Epoch 72/100\n",
            "580/580 [==============================] - 19s 32ms/step - loss: 0.9990 - accuracy: 0.6225 - val_loss: 1.5868 - val_accuracy: 0.4862\n",
            "Epoch 73/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 0.9953 - accuracy: 0.6210 - val_loss: 1.3399 - val_accuracy: 0.5323\n",
            "Epoch 74/100\n",
            "580/580 [==============================] - 18s 32ms/step - loss: 0.9940 - accuracy: 0.6273 - val_loss: 1.7174 - val_accuracy: 0.4851\n",
            "Epoch 75/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 0.9880 - accuracy: 0.6255 - val_loss: 1.4807 - val_accuracy: 0.5315\n",
            "Epoch 76/100\n",
            "580/580 [==============================] - 18s 32ms/step - loss: 0.9890 - accuracy: 0.6307 - val_loss: 1.3599 - val_accuracy: 0.5341\n",
            "Epoch 77/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 0.9801 - accuracy: 0.6279 - val_loss: 1.3914 - val_accuracy: 0.5373\n",
            "Epoch 78/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 0.9766 - accuracy: 0.6297 - val_loss: 1.2554 - val_accuracy: 0.5644\n",
            "Epoch 79/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 0.9788 - accuracy: 0.6331 - val_loss: 1.8362 - val_accuracy: 0.4388\n",
            "Epoch 80/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 0.9719 - accuracy: 0.6362 - val_loss: 1.5132 - val_accuracy: 0.4976\n",
            "Epoch 81/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 0.9683 - accuracy: 0.6333 - val_loss: 1.3363 - val_accuracy: 0.5483\n",
            "Epoch 82/100\n",
            "580/580 [==============================] - 20s 35ms/step - loss: 0.9675 - accuracy: 0.6383 - val_loss: 1.5057 - val_accuracy: 0.5119\n",
            "Epoch 83/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 0.9582 - accuracy: 0.6398 - val_loss: 1.4375 - val_accuracy: 0.5450\n",
            "Epoch 84/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 0.9513 - accuracy: 0.6400 - val_loss: 1.3823 - val_accuracy: 0.5233\n",
            "Epoch 85/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 0.9536 - accuracy: 0.6409 - val_loss: 1.2619 - val_accuracy: 0.5728\n",
            "Epoch 86/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 0.9436 - accuracy: 0.6461 - val_loss: 1.3393 - val_accuracy: 0.5481\n",
            "Epoch 87/100\n",
            "580/580 [==============================] - 18s 32ms/step - loss: 0.9422 - accuracy: 0.6432 - val_loss: 1.4631 - val_accuracy: 0.5207\n",
            "Epoch 88/100\n",
            "580/580 [==============================] - 18s 31ms/step - loss: 0.9374 - accuracy: 0.6450 - val_loss: 1.5289 - val_accuracy: 0.5108\n",
            "Epoch 89/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 0.9300 - accuracy: 0.6473 - val_loss: 1.6010 - val_accuracy: 0.5131\n",
            "Epoch 90/100\n",
            "580/580 [==============================] - 18s 32ms/step - loss: 0.9340 - accuracy: 0.6503 - val_loss: 1.5414 - val_accuracy: 0.5190\n",
            "Epoch 91/100\n",
            "580/580 [==============================] - 19s 32ms/step - loss: 0.9307 - accuracy: 0.6489 - val_loss: 1.3677 - val_accuracy: 0.5541\n",
            "Epoch 92/100\n",
            "580/580 [==============================] - 19s 33ms/step - loss: 0.9205 - accuracy: 0.6539 - val_loss: 1.2948 - val_accuracy: 0.5569\n",
            "Epoch 93/100\n",
            "580/580 [==============================] - 18s 32ms/step - loss: 0.9172 - accuracy: 0.6522 - val_loss: 1.2765 - val_accuracy: 0.5653\n",
            "Epoch 94/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 0.9124 - accuracy: 0.6593 - val_loss: 1.2917 - val_accuracy: 0.5722\n",
            "Epoch 95/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 0.9143 - accuracy: 0.6565 - val_loss: 1.3001 - val_accuracy: 0.5741\n",
            "Epoch 96/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 0.9092 - accuracy: 0.6582 - val_loss: 1.3160 - val_accuracy: 0.5746\n",
            "Epoch 97/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 0.9034 - accuracy: 0.6634 - val_loss: 1.5490 - val_accuracy: 0.5024\n",
            "Epoch 98/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 0.9026 - accuracy: 0.6608 - val_loss: 1.3151 - val_accuracy: 0.5491\n",
            "Epoch 99/100\n",
            "580/580 [==============================] - 20s 34ms/step - loss: 0.8949 - accuracy: 0.6629 - val_loss: 1.4126 - val_accuracy: 0.5446\n",
            "Epoch 100/100\n",
            "580/580 [==============================] - 19s 32ms/step - loss: 0.8912 - accuracy: 0.6636 - val_loss: 1.6890 - val_accuracy: 0.4845\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc5aa9527f0>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the output of the model\n",
        "output = model.predict(images_test)\n",
        "\n",
        "# Compute the mean and standard deviation of the output\n",
        "#mean = K.mean(output)\n",
        "#std = K.std(output)\n",
        "\n",
        "#print('Mean:', mean)\n",
        "#print('Standard deviation:', std)"
      ],
      "metadata": {
        "id": "CRku8685oWI1",
        "outputId": "11991c55-2ba4-4e1f-bffd-fc0c5688e35d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "182/182 [==============================] - 2s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the best weights\n",
        "model.load_weights(checkpoint_file_path)\n",
        "\n",
        "# evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(images_test, y_test, verbose=0)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "-I5VmTVniJXf",
        "outputId": "5e6b85c4-3eca-48af-87fb-4a59380e4305",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5663793087005615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Above table potrarys that the DCNN and CNN models are the superior models for Emotion Classification dataset. The validation accuracy of both the models are 0.6834 and 0.6338 respectively are the best model since we are hypertuning the CNN with multiple layers to achieve high accuracy. \n",
        "\n",
        "Also, when we are using the DNN with learning rate of 0.0001 and a batch size of 128 after 30 epochs the model achieved 0.4088 validation accuracy. As it can be seen towards the end of training (epoch 26) the model started to overfit. This is not a good performing learning rate since the model is hypertuned to most parameters. the reason for this unusual behavior is unknown and can be a study for our future prespective.\n",
        "\n",
        "Now the ML model as per our expectation the Random forest and SVM preforms slightly better than the Logistic regression since the data is sparse and categorical.Though we gained the maximum accuracy from the SVM i.e. 0.4418. It is unlikely that the ML would perform better for this dataset. Thus, ML algorithm has its limitation.\n",
        "\n",
        "Now lastly for transfer learning, we investigated on many pre-trained algorithm such as EfficientNet, MobileNet, RestNet, and many others and have optimally caliberated the parameters, however, we did not see any reasonable chnages in transfer learning accuracy. We only provided the MobileNet algorithm for a reference. The performance of the MobileNet model was enhanced and overfitting was decreased by data augmentation. Finally we can get accuracy as 0.4845 but it is still low compared to the DCNN and CNN by a significant amount. But this accuracy is higher than ML basic and DNN so can be preffered over them. We have not show the output of standard deviation and mean since there was a compilation error, but have calculated it individually. \n",
        "\n",
        "Our future prospect would be to have various data augmentation methods implemented, such as scaling and shearing, to produce more varied training data. To further enhance the model's performance, hyperparameter adjustment might be used for all the models."
      ],
      "metadata": {
        "id": "E_KqyTG3lDt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Discussion:\n",
        "\n",
        "According to the results the best performing model for this task was the DCNN which achieved the highest accuracy among all the models that were used. Its complex architecture seems to be able to handle this particular dataset much better than the other models, and predict the target label (emotion) more effectively, achieving a validation accuracy 0.6834 and test accuracy 0.6525 in Kaggle, while the next best performing model achieved 0.6338. Additionally, the DCNN model required less computational power compared to other complex models such as MobileNet, and converged faster which makes it more efficient. Therefore, the model that we would recommend for the emotions recognition task is the DCNN. \n",
        "\n",
        "When it comes to what further steps we could take to get better wins for this task, there are several things that we could do. The first thing would be to experiment with even more different configurations of the models such as fine-tuning hyperparameters and trying different activation functions. Additionally, as there are various transfer learning models, there is a lot of room for experimenting with many of these models to find the one that performs the best for this particular dataset. Also, another thing that we believe that could help is the use of cross-validation in order to get a robust performance."
      ],
      "metadata": {
        "id": "t3ssSn8dlGmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reference:\n",
        "\n",
        "[1] J. Brownlee, “A Gentle Introduction to the Rectified Linear Unit (ReLU) for Deep Learning Neural Networks,” Machine Learning Mastery, Apr. 20, 2019. https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/\n",
        "\n",
        "[2] S. Krishnan, “How to determine the number of layers and neurons in the hidden layer?,” Medium, Sep. 10, 2021. https://medium.com/geekculture/introduction-to-neural-network-2f8b8221fbd3 \n",
        "\n",
        "[3] J. Brownlee, “Softmax Activation Function with Python,” Machine Learning Mastery, Oct. 18, 2020. https://machinelearningmastery.com/softmax-activation-function-with-python/"
      ],
      "metadata": {
        "id": "weTfi1spBWWV"
      }
    }
  ]
}